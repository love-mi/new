{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 电池数据异常检测\n",
    "### 此notebook为异常检测比赛的参考DEMO，包括数据划分、模型训练和结果检测等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 17:58:21.258864: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder, check_array, inner_autoencoder, check_is_fitted, \\\n",
    "    pairwise_distances_no_broadcast\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载训练集的pkl文件\n",
    "\n",
    "训练集的label存放在pkl里面，可以通过它并区分正常片段和异常片段  \n",
    "注意需要输入训练集对应的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/home/min/vloong-Anomaly-detection/repo_template/train'#存放数据的路径\n",
    "pkl_files = glob(data_path+'/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 28389/28389 [00:09<00:00, 2972.86it/s]\n"
     ]
    }
   ],
   "source": [
    "ind_pkl_files = []#存放标签为0的文件\n",
    "ood_pkl_files = []#存放标签为1的文件\n",
    "for each_path in tqdm(pkl_files):\n",
    "    this_pkl_file = torch.load(each_path)#下载pkl文件\n",
    "    if this_pkl_file[1]['label'] == '00':\n",
    "        ind_pkl_files.append(each_path)\n",
    "    else:\n",
    "        ood_pkl_files.append(each_path)\n",
    "\n",
    "random.seed(0)\n",
    "#排序并打乱存放车辆序号的集合\n",
    "random.shuffle(ind_pkl_files)\n",
    "random.shuffle(ood_pkl_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集和测试集  \n",
    "\n",
    "参赛选手可以根据需求自由化分数据集\n",
    "\n",
    "这里选取训练集中正常片段的1/4作为训练集，正常片段的剩余3/4和异常片段作为测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_files=[]\n",
    "for i in range(len(ind_pkl_files)//4):\n",
    "    train_pkl_files.append(ind_pkl_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pkl_files=[]\n",
    "for j in range(len(ind_pkl_files)//4,len(ind_pkl_files)):\n",
    "    test_pkl_files.append(ind_pkl_files[j])\n",
    "for item in ood_pkl_files:\n",
    "    test_pkl_files.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义加载函数，并对数据进行正则化  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  load_data(pkl_list,label=True):\n",
    "    '''\n",
    "    输入pkl的列表，进行文件加载\n",
    "    label=True用来加载训练集\n",
    "    label=False用来加载真正的测试集，真正的测试集无标签\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "\n",
    "    for  each_pkl in pkl_list:\n",
    "        item = torch.load(each_pkl)\n",
    "        # 此处选取的是每个滑窗的最后一条数据，仅供参考，可以选择其他的方法，比如均值或者其他处理时序数据的网络\n",
    "        # 此处选取了前7个特征，可以需求选取特征数量\n",
    "        X.append(item[0][:,0:7][-1])\n",
    "        if label:\n",
    "            y.append(int(item[1]['label'][0]))\n",
    "    X = np.vstack(X)\n",
    "    if label:\n",
    "        y = np.vstack(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=load_data(train_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=load_data(test_pkl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mean = np.mean(X_train, axis=0)\n",
    "_std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - _mean) / (_std + 1e-4)\n",
    "X_test = (X_test - _mean) / (_std + 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义DataLoader数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyODDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyOD Dataset class for PyTorch Dataloader\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y=None, mean=None, std=None):\n",
    "        super(PyODDataset, self).__init__()\n",
    "        self.X = X\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()#将tensor类型转换列表格式\n",
    "        sample = self.X[idx, :]\n",
    "\n",
    "        # if self.mean.any():\n",
    "        #     sample = (sample - self.mean) / (self.std + 1e-5)\n",
    "        #torch.from_numpy()将numpy类型转换为tensor类型\n",
    "        return torch.from_numpy(sample), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义AutoEncoder类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Car_AutoEncoder(AutoEncoder):\n",
    "    \n",
    "    '''\n",
    "    使用autoencoder 来进行模型的训练，默认采用无监督的训练方式\n",
    "    '''\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # validate inputs X and y (optional)\n",
    "        X = check_array(X)\n",
    "        self._set_n_classes(y)\n",
    "\n",
    "        n_samples, n_features = X.shape[0], X.shape[1] #获取样本个数和特征个数\n",
    "\n",
    "        # 是否进行预处理操作\n",
    "        if self.preprocessing:\n",
    "            self.mean, self.std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "            train_set = PyODDataset(X=X, mean=self.mean, std=self.std)\n",
    "\n",
    "        else:\n",
    "            train_set = PyODDataset(X=X)\n",
    "        #构建数据生成器\n",
    "        train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                                   batch_size=self.batch_size,\n",
    "                                                   shuffle=False)\n",
    "\n",
    "        # initialize the model ,初始化模型\n",
    "        #hidden_neurons列表，可选（默认值为[64， 32]）每个隐藏层的神经元数。因此，该网络的结构为[n_features，64，32，32，64，n_features]\n",
    "        #hidden_activationstr，可选（默认值='relu'）用于隐藏层的激活函数。所有隐藏层都强制使用相同类型的激活\n",
    "        #batch_norm布尔值，可选（默认值为 True）是否应用批量规范化。\n",
    "        #dropout_rate浮点数 （0.， 1），可选（默认值 = 0.2）要跨所有层使用的分级。\n",
    "        \n",
    "        self.model = inner_autoencoder(\n",
    "            n_features=n_features,\n",
    "            hidden_neurons=self.hidden_neurons,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            batch_norm=self.batch_norm,\n",
    "            hidden_activation=self.hidden_activation)\n",
    "\n",
    "        #将model放入device中\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        # 训练自动编码器以找到最佳编码器\n",
    "        self._train_autoencoder(train_loader)\n",
    "\n",
    "        self.model.load_state_dict(self.best_model_dict)\n",
    "        self.decision_scores_ = self.decision_function(X)#获得输入样本的异常得分\n",
    "        \n",
    "        self._process_decision_scores()  \n",
    "        return self\n",
    "\n",
    "    def decision_function(self, X): \n",
    "        \"\"\"使用拟合的检测器预测X的原始异常分数。\n",
    "\n",
    "            输入样本的异常分数是基于不同的检测器算法。为保持一致性，离群值分配为异常分数越大的。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape (n_samples, n_features)\n",
    "            形状的numpy数组（n_samples，n_features）训练输入样本。仅接受稀疏矩阵，如果它们由基础估计器支持。\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        anomaly_scores : numpy array of shape (n_samples,)\n",
    "            形状的numpy数组（n_samples，）输入样本的异常得分。\n",
    "        \"\"\"\n",
    "        #对估算器执行is_fitted验证。通过验证是否存在拟合属性（以下划线结尾）来检查估计量是否拟合，否则通过给定消息引发NotFittedError。此实用程序旨在由估计器本身在内部使用，通常在其自己的预测/变换方法中使用。\n",
    "        check_is_fitted(self, ['model', 'best_model_dict'])\n",
    "        # X = check_array(X)\n",
    "\n",
    "        # note the shuffle may be true but should be False\n",
    "        if self.preprocessing:\n",
    "            dataset = PyODDataset(X=X, mean=self.mean, std=self.std)\n",
    "        else:\n",
    "            dataset = PyODDataset(X=X)\n",
    "\n",
    "        dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                                 batch_size=self.batch_size,\n",
    "                                                 shuffle=False) #要设置为False\n",
    "        # enable the evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # construct the vector for holding the reconstruction error\n",
    "        outlier_scores = np.zeros([X.shape[0], ])#形状为（X.shape[0],)\n",
    "        with torch.no_grad():\n",
    "            for data, data_idx in dataloader:\n",
    "                data_cuda = data.to(self.device).float()\n",
    "                # this is the outlier score\n",
    "                outlier_scores[data_idx] = pairwise_distances_no_broadcast(\n",
    "                    data, self.model(data_cuda).cpu().numpy())\n",
    "\n",
    "        return outlier_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义训练和评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了便于复现这里固定了随机种子\n",
    "def same_seeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  \n",
    "    np.random.seed(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "def train(X_train,X_test,hidden_neurons,learning_rate,epochs,batch_size,contamination,drop_out,hidden_activation):\n",
    "    same_seeds(42)\n",
    "    clf_name = 'auto_encoder'\n",
    "    clf = Car_AutoEncoder(hidden_neurons=hidden_neurons,  batch_size=batch_size, epochs=epochs,learning_rate=learning_rate,\n",
    "                                    dropout_rate=drop_out,contamination=contamination,hidden_activation=hidden_activation)\n",
    "    clf.fit(X_train)\n",
    "\n",
    "    y_train_pred = clf.labels_ # 返回训练数据上的分类标签 (0: 正常值, 1: 异常值) # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # 返回训练数据上的异常值 (分值越大越异常)# raw outlier scores\n",
    "    y_test_pred = clf.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "    y_test_scores = clf.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n",
    "    return clf, y_test_scores\n",
    "\n",
    "def evaluate(label,score):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(label, score, pos_label=1)\n",
    "    AUC = auc(fpr, tpr)\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的训练和AUC计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义合适的参数\n",
    "hidden_neurons=[ 64,128,128,64]\n",
    "learning_rate=0.02\n",
    "epochs=50\n",
    "batch_size=640\n",
    "contamination=0.005\n",
    "drop_out=0.2\n",
    "hidden_activation='sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: training loss 0.83499715924263 \n",
      "epoch 1: training loss 0.508006152510643 \n",
      "epoch 2: training loss 0.478377440571785 \n",
      "epoch 3: training loss 0.46995710730552676 \n",
      "epoch 4: training loss 0.455228129029274 \n",
      "epoch 5: training loss 0.44920630753040314 \n",
      "epoch 6: training loss 0.427818164229393 \n",
      "epoch 7: training loss 0.39976899027824403 \n",
      "epoch 8: training loss 0.38707375824451445 \n",
      "epoch 9: training loss 0.37535335719585416 \n",
      "epoch 10: training loss 0.36480623185634614 \n",
      "epoch 11: training loss 0.3499638170003891 \n",
      "epoch 12: training loss 0.3335436999797821 \n",
      "epoch 13: training loss 0.3083561807870865 \n",
      "epoch 14: training loss 0.302016681432724 \n",
      "epoch 15: training loss 0.29258138239383696 \n",
      "epoch 16: training loss 0.2819209784269333 \n",
      "epoch 17: training loss 0.2840063750743866 \n",
      "epoch 18: training loss 0.2781553566455841 \n",
      "epoch 19: training loss 0.27419638335704805 \n",
      "epoch 20: training loss 0.2750765323638916 \n",
      "epoch 21: training loss 0.2753778547048569 \n",
      "epoch 22: training loss 0.27093194276094434 \n",
      "epoch 23: training loss 0.27201459407806394 \n",
      "epoch 24: training loss 0.2724082231521606 \n",
      "epoch 25: training loss 0.2745064958930016 \n",
      "epoch 26: training loss 0.2743145078420639 \n",
      "epoch 27: training loss 0.27066424638032915 \n",
      "epoch 28: training loss 0.27482669055461884 \n",
      "epoch 29: training loss 0.2731095552444458 \n",
      "epoch 30: training loss 0.2670728012919426 \n",
      "epoch 31: training loss 0.26916364431381223 \n",
      "epoch 32: training loss 0.27016029953956605 \n",
      "epoch 33: training loss 0.2750635892152786 \n",
      "epoch 34: training loss 0.27493434548377993 \n",
      "epoch 35: training loss 0.2686493456363678 \n",
      "epoch 36: training loss 0.27206680476665496 \n",
      "epoch 37: training loss 0.2740051180124283 \n",
      "epoch 38: training loss 0.26581997871398927 \n",
      "epoch 39: training loss 0.2690639913082123 \n",
      "epoch 40: training loss 0.27092536091804503 \n",
      "epoch 41: training loss 0.26882582902908325 \n",
      "epoch 42: training loss 0.27108412981033325 \n",
      "epoch 43: training loss 0.2688520342111588 \n",
      "epoch 44: training loss 0.26644359081983565 \n",
      "epoch 45: training loss 0.26616286635398867 \n",
      "epoch 46: training loss 0.2734403759241104 \n",
      "epoch 47: training loss 0.26970794796943665 \n",
      "epoch 48: training loss 0.26979583501815796 \n",
      "epoch 49: training loss 0.27128407955169676 \n"
     ]
    }
   ],
   "source": [
    "same_seeds(42)\n",
    "clf = Car_AutoEncoder(hidden_neurons=hidden_neurons,  batch_size=batch_size, epochs=epochs,learning_rate=learning_rate,\n",
    "                                     dropout_rate=drop_out,contamination=contamination,hidden_activation=hidden_activation)\n",
    "clf.fit(X_train)\n",
    "y_test_pred = clf.predict(X_test) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_test_scores = clf.decision_function(X_test)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6887876776808659"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC1=evaluate(y_test,y_test_scores)\n",
    "AUC1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的保存、加载和提交文件生成  \n",
    "\n",
    "需要输入测试数据的路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存和加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(clf,\"clf1.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car_AutoEncoder(batch_norm=True, batch_size=640, contamination=0.005,\n",
       "        device=device(type='cpu'), dropout_rate=0.2, epochs=15,\n",
       "        hidden_activation='sigmoid', hidden_neurons=[32, 64, 64, 32],\n",
       "        learning_rate=0.03, loss_fn=MSELoss(), preprocessing=True,\n",
       "        weight_decay=1e-05)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=torch.load(\"clf1.torch\")\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path3='/home/min/vloong-Anomaly-detection/repo_template/test_A'\n",
    "test1_files = glob(data_path3+'/*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val,_=load_data(test1_files,label=False)\n",
    "_mean = np.mean(X_val, axis=0)\n",
    "_std = np.std(X_val, axis=0)\n",
    "X_val = (X_val - _mean) / (_std + 1e-4)\n",
    "y_val_pred = clf.predict(X_val) # 返回未知数据上的分类标签 (0: 正常值, 1: 异常值) # outlier labels (0 or 1)\n",
    "y_val_scores = clf.decision_function(X_val)   #返回未知数据上的异常值 (分值越大越异常) # outlier scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 6234/6234 [00:00<00:00, 354890.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "#记录文件名和对应的异常得分\n",
    "predict_result={}\n",
    "for i in tqdm(range(len(test1_files))):\n",
    "    file=test1_files[i]\n",
    "    #如果是window系统：\n",
    "    if platform.system().lower() == 'windows':\n",
    "        name=file.split('\\\\')[-1]\n",
    "    #如果是linux系统\n",
    "    elif platform.system().lower() == 'linux':\n",
    "        name=file.split('/')[-1]\n",
    "    predict_result[name]=y_val_scores[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6387.pkl</td>\n",
       "      <td>0.927133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3382.pkl</td>\n",
       "      <td>0.758415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5525.pkl</td>\n",
       "      <td>0.621016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5468.pkl</td>\n",
       "      <td>0.554446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8606.pkl</td>\n",
       "      <td>0.778990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>2225.pkl</td>\n",
       "      <td>0.793437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>3846.pkl</td>\n",
       "      <td>0.461130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>9864.pkl</td>\n",
       "      <td>0.818715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>4059.pkl</td>\n",
       "      <td>0.409528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>7017.pkl</td>\n",
       "      <td>0.439635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6234 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name     score\n",
       "0     6387.pkl  0.927133\n",
       "1     3382.pkl  0.758415\n",
       "2     5525.pkl  0.621016\n",
       "3     5468.pkl  0.554446\n",
       "4     8606.pkl  0.778990\n",
       "...        ...       ...\n",
       "6229  2225.pkl  0.793437\n",
       "6230  3846.pkl  0.461130\n",
       "6231  9864.pkl  0.818715\n",
       "6232  4059.pkl  0.409528\n",
       "6233  7017.pkl  0.439635\n",
       "\n",
       "[6234 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score=pd.DataFrame(list(predict_result.items()),columns=['file_name','score'])#列名必须为这俩个\n",
    "predict_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_score.to_csv('submision.csv',index = False) #保存为比赛要求的csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6387.pkl</td>\n",
       "      <td>0.927133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3382.pkl</td>\n",
       "      <td>0.758415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5525.pkl</td>\n",
       "      <td>0.621016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5468.pkl</td>\n",
       "      <td>0.554446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8606.pkl</td>\n",
       "      <td>0.778990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2511.pkl</td>\n",
       "      <td>0.848401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5153.pkl</td>\n",
       "      <td>1.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4974.pkl</td>\n",
       "      <td>0.637358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9962.pkl</td>\n",
       "      <td>0.416316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3795.pkl</td>\n",
       "      <td>0.619432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_name     score\n",
       "0  6387.pkl  0.927133\n",
       "1  3382.pkl  0.758415\n",
       "2  5525.pkl  0.621016\n",
       "3  5468.pkl  0.554446\n",
       "4  8606.pkl  0.778990\n",
       "5  2511.pkl  0.848401\n",
       "6  5153.pkl  1.217900\n",
       "7  4974.pkl  0.637358\n",
       "8  9962.pkl  0.416316\n",
       "9  3795.pkl  0.619432"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
